# Custom Embeddings

This hands-on lab demonstrates how you can build custom embeddings with TATK using two state-of-the-art word embedding methods - word2Vec and fastText.

In this lab, we will:
- Understand word embeddings and the technique(s) behind getting word representation
- Use Pubmed database to create the word embedding pipeline
- Train word2Vec/fastText models and evaluate
- Save and load pipeline for additional training
- Identify semantically similar terms

### Learning Objectives ###

The objectives of this lab are to:

- Understand the concept of word representations for predicting surrounding context
- Understand the difference between the two embedding methods - word2Vec and fastText
- Learn how to create word embedding pipeline, train and evaluate the models
- Understand how you can identify semantically similar terms using word embeddings